---
title: "Cw3"
author: "Fabian Wieczorek"
format: html
self-contained: true
---

## Biblioteki

Bilioteki użyte w ćwiczeniu/lub przydatne.

```{r}
library(lubridate)
library(ggpubr)
library(tidymodels) 
library(skimr) 
library(GGally) 
library(openair) 
library(ranger)
library(modeldata)
library(tidymodels)
tidymodels_prefer()
```
Instalacja biblioteki ranger
```{r}
install.packages('ranger')
```
## Wczytanie danych

```{r}
air <- mydata |> selectByDate(year = 2002)
air |> skim()
```

Sprawdzenie braków danych.

```{r}
air |> is.na() |> as_tibble() |> summarise_all(sum)
```
Usunięcia braków danych.

```{r}
air <- air |> na.omit()
```

Oznaczanie wysokiego i niskiego stężenia ozonu w powietrzu.

```{r}
air <- 
  air |> 
  mutate(ozone =cut(
    o3,
    breaks = c(-0.1, 10, 53),
    labels = c("Niskie", "Wysokie")
  ))
```

Sprawdzenie wyniku poprzedniego działania.

```{r}
air |> count(ozone)
```

Działa poprawienie.

## Podzielenie danych na treningowe i testowe

```{r}
set.seed(123)
data_split <-  initial_split(air, prop = 3/4, strata = ozone)
train_data <- training(data_split)
test_data <- testing(data_split)
```

Sprawdzenie liczebność jak został podzielony zbiór danych.

```{r}
nrow(train_data); nrow(test_data)
```

Wygląda sensownie. Ciekawe czy funkcja robi shuffle?

Sprawdzenie czy funkcja odpowiednio podzieliła ozone.

```{r}
test_data |> 
  count(ozone) |> 
  mutate(prop = n/sum(n))
```

Pięknie mamy udizał taki jak mniej więcej zakładaliśmy.

Teraz to samo dla zbioru uczącego.

```{r}
train_data |> 
  count(ozone) |> 
  mutate(prop = n/sum(n))
```
dokładnie ten sam efekt.

*Dane w przypadku algorytmu lasu losowego nie będą dodatkowo przetwarzane. Zobaczymy czy algorytm poradzi sobie na takich danych*

## Model RF - random forest

Metoda dopasowania użyta w modelu lasu losowego to `ranger`.

```{r}
rf_mod <- 
  rand_forest() |> 
  set_engine("ranger") |> 
  set_mode("classification")
```

Las losowy do działa potrzebuje wykorzystać liczby pseudolosowe to zapoczątkowania budowania drzew decyzycjnych na losowych częściach zbioru treningowego. Po to zostaje ustawione ziarno w celu walidacji późniejszych prób i różnież by wyniki nie były zbyt "losowe" w przypadku wielokrotnego uruchamiania skryptu.

```{r}
set.seed(234)
rf_fit <- 
  rf_mod |> 
  fit(ozone ~ ., data = train_data)
rf_fit
```

Jak można zauważyć las losowy wygenerował 500 drzew decyzyjnych. Ilość próbek to 5666.

### Predykcja w lesie losowym

Predycji dokonamy najpierw na zbiorze treningowym.

```{r}
rf_pred_train <- 
  predict(rf_fit, new_data = train_data) |> 
  bind_cols(predict(rf_fit, new_data = train_data, type = "prob")) |> 
  bind_cols(train_data |> select(ozone))

# Krzywa ROC
rf_pred_train |> 
  roc_curve(truth = ozone, .pred_Niskie) |> 
  autoplot()
```

Jak widać model jest totalnie przeuczony. Powodem tego może być nie usunięcie parametru nox.

Sprawdźmy teraz pole pod krzywą ROC

```{r}
rf_pred_train |> 
  roc_auc(truth = ozone, .pred_Niskie)
```
Pole wynosi 1 czyli wartość maksymalną.

Sprawdźmy jeszcze dokładność.

```{r}
rf_pred_train |> 
  accuracy(truth = ozone, .pred_class)
```

Model ma idealne zaklasyfikowanie danych na których się uczył.
***
Teraz zróbmy to samo na danych testowych, czyli takich których model nigdy nie widział.

```{r}
print(rf_pred_train)
```






