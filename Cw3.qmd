---
title: "Cw3"
author: "Fabian Wieczorek"
format: html
self-contained: true
---

## Biblioteki

Bilioteki użyte w ćwiczeniu/lub przydatne.

```{r}
library(lubridate)
library(ggpubr)
library(tidymodels) 
library(skimr) 
library(GGally) 
library(openair) 
library(ranger)
library(modeldata)
library(tidymodels)
tidymodels_prefer()
```
Instalacja biblioteki ranger
```{r}
install.packages('ranger')
```
## Wczytanie danych

```{r}
air <- mydata |> selectByDate(year = 2002)
air |> skim()
```

Sprawdzenie braków danych.

```{r}
air |> is.na() |> as_tibble() |> summarise_all(sum)
```
Usunięcia braków danych.

```{r}
air <- air |> na.omit()
```

Oznaczanie wysokiego i niskiego stężenia ozonu w powietrzu.

```{r}
air <- 
  air |> 
  mutate(ozone =cut(
    o3,
    breaks = c(-0.1, 10, 53),
    labels = c("Niskie", "Wysokie")
  ))
```

Sprawdzenie wyniku poprzedniego działania.

```{r}
air |> count(ozone)
```

Działa poprawienie.

## Podzielenie danych na treningowe i testowe

```{r}
set.seed(123)
data_split <-  initial_split(air, prop = 3/4, strata = ozone)
train_data <- training(data_split)
test_data <- testing(data_split)
```

Sprawdzenie liczebność jak został podzielony zbiór danych.

```{r}
nrow(train_data); nrow(test_data)
```

Wygląda sensownie. Ciekawe czy funkcja robi shuffle?

Sprawdzenie czy funkcja odpowiednio podzieliła ozone.

```{r}
test_data |> 
  count(ozone) |> 
  mutate(prop = n/sum(n))
```

Pięknie mamy udizał taki jak mniej więcej zakładaliśmy.

Teraz to samo dla zbioru uczącego.

```{r}
train_data |> 
  count(ozone) |> 
  mutate(prop = n/sum(n))
```
dokładnie ten sam efekt.

*Dane w przypadku algorytmu lasu losowego nie będą dodatkowo przetwarzane. Zobaczymy czy algorytm poradzi sobie na takich danych*

## Model RF - random forest

Metoda dopasowania użyta w modelu lasu losowego to `ranger`.

```{r}
rf_mod <- 
  rand_forest() |> 
  set_engine("ranger") |> 
  set_mode("classification")
```

Las losowy do działa potrzebuje wykorzystać liczby pseudolosowe to zapoczątkowania budowania drzew decyzycjnych na losowych częściach zbioru treningowego. Po to zostaje ustawione ziarno w celu walidacji późniejszych prób i różnież by wyniki nie były zbyt "losowe" w przypadku wielokrotnego uruchamiania skryptu.

```{r}
set.seed(234)
rf_fit <- 
  rf_mod |> 
  fit(ozone ~ ., data = train_data)
rf_fit
```

Jak można zauważyć las losowy wygenerował 500 drzew decyzyjnych. Ilość próbek to 5666.

### Predykcja w lesie losowym

Predycji dokonamy najpierw na zbiorze treningowym.

```{r}
rf_pred_train <- 
  predict(rf_fit, new_data = train_data) |> 
  bind_cols(predict(rf_fit, new_data = train_data, type = "prob")) |> 
  bind_cols(train_data |> select(ozone))

# Krzywa ROC
rf_pred_train |> 
  roc_curve(truth = ozone, .pred_Niskie) |> 
  autoplot()
```

Jak widać model jest totalnie przeuczony. Powodem tego może być nie usunięcie parametru nox.

Sprawdźmy teraz pole pod krzywą ROC

```{r}
rf_pred_train |> 
  roc_auc(truth = ozone, .pred_Niskie)
```
Pole wynosi 1 czyli wartość maksymalną.

Sprawdźmy jeszcze dokładność.

```{r}
rf_pred_train |> 
  accuracy(truth = ozone, .pred_class)
```

Model ma idealne zaklasyfikowanie danych na których się uczył.
***
Teraz zróbmy to samo na danych testowych, czyli takich których model nigdy nie widział.

```{r}
rf_pred_test <- 
  predict(rf_fit, new_data = test_data) |> 
  bind_cols(predict(rf_fit, new_data = test_data, type = "prob")) |> 
  bind_cols(test_data |> select(ozone))

# Krzywa rock
rf_pred_test |> 
  roc_curve(truth = ozone, .pred_Niskie) |> 
  autoplot()
```


O dziwo model też bardzo dobrze sobie radzi na danych testowych

```{r}
rf_pred_test |> 
  roc_auc(truth = ozone, .pred_Niskie)
```

```{r}
rf_pred_test |> 
  accuracy(truth = ozone, .pred_class)
```
## Wykorzysatnie różnych metod resamplingu

Przygotowanie danych do resamplingu

```{r}
set.seed(123)
folds_v5 <- vfold_cv(train_data, v = 5)
folds_v10 <- vfold_cv(train_data, v = 10)
folds_boot <- bootstraps(train_data, times = 30)
```


Przepis z poprzedniego ćwiczenia.

```{r}
rec <- recipe(ozone ~ ., data = train_data) |>
  update_role(date, new_role = "ID") |>  
  step_date(date, features = c("dow", "month")) |>  
  step_holiday(date,
               holidays = timeDate::listHolidays("US"),  
               keep_original_cols = FALSE) |>
  step_dummy(all_nominal_predictors()) |>
  step_zv(all_predictors()) |> 
  step_rm(nox) |> 
  step_YeoJohnson(all_numeric_predictors()) |> 
  step_normalize(all_numeric_predictors())
```

Workflow:

```{r}
rf_work <- 
  workflow() |> 
  add_model(rf_mod) |> 
  add_recipe(rec)
```

Ocena przy pomocy 5-krotnej CV

```{r}
rf_rs_v5 <- fit_resamples(
  rf_work,
  resample = folds_v5,
  metrics = metric_set(accuracy, roc_auc)
)
collect_metrics(rf_rs_v5)
```

Ocena przy pomocy 10-krotnej CV

```{r}
rf_rs_v10 <- fit_resamples(
  rf_work,
  resamples = folds_v10,
  metrics = metric_set(accuracy, roc_auc)
)
collect_metrics(rf_rs_v10)
```

Ocena przy pomocy bootstrapu

```{r}
rf_rs_boot <- fit_resamples(
  rf_work,
  resamples = folds_boot,
  metrics = metric_set(accuracy, roc_auc)
)
collect_metrics(rf_rs_boot)
```





